{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First lesson: Tensor Math and Comparison Operations: \n",
    "-  Tensor indexing\n",
    "-  Tensor Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. what is a tensor and how to create a tensor?\n",
    "- Tensor is multi-dimentional matrix containing elements of a single data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor = torch.tensor([[1,2,3],[4,5,6]])\n",
    "my_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Can we also set the type while initializing? Yes\n",
    "3. How?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor = torch.tensor([[1,2,3],[4,5,6]],dtype=torch.float32)\n",
    "my_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]], device='cuda:0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "my_tensor =  torch.tensor([[1,2,3],[4,5,6]],device=device)\n",
    "my_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "cuda:0\n",
      "torch.Size([2, 3])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(my_tensor.dtype)\n",
    "print(my_tensor.device)\n",
    "print(my_tensor.shape) # 2 rows and 3 columns\n",
    "print(my_tensor.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0.1035, 0.3877, 0.7842],\n",
      "        [0.9629, 0.5405, 0.9829],\n",
      "        [0.4155, 0.2939, 0.7920]], dtype=torch.float16)\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1]], dtype=torch.int16)\n",
      "torch.float32\n",
      "torch.float32\n",
      "torch.float16\n",
      "torch.float32\n",
      "torch.int16\n",
      "tensor([[1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1]], dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "# create an zero 3*3 tensor\n",
    "x = torch.empty(size = (3,3))\n",
    "print(x)\n",
    "\n",
    "y = torch.zeros(3,3)\n",
    "print(y)\n",
    "\n",
    "# initializing random tensors\n",
    "f = torch.rand(3,3, dtype=torch.float16)\n",
    "print(f)\n",
    "\n",
    "# initializing ones tensor\n",
    "z = torch.ones(3,3)\n",
    "print(z)\n",
    "\n",
    "# initializing identical tensor\n",
    "i = torch.eye(5,5, dtype=torch.int16)\n",
    "print(i)\n",
    "\n",
    "# remember by default the data type is float32 in tensors\n",
    "print(x.dtype)\n",
    "print(y.dtype)\n",
    "print(f.dtype)\n",
    "print(z.dtype)\n",
    "print(i.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(start=0, end=5, step=1) # this is kind range, which we apply in loop \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000, 0.9000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.linspace(start=0.1,end=1,steps=10) # this fuction also work as loop\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n.b: remember that torch is core library of pytorch framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6199,  0.4872, -0.0413,  1.3820, -1.1765]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(1,5).normal_(mean=0,std=1) # initializing normal distribution, here std is standard deviation.\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5779, 0.8102, 0.9275, 0.1023, 0.7566]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(1,5).uniform_(0,1) # initializing uniform distribution\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.diag(torch.ones(3)) # another way to initialize identity matrix\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to initialize and convert tensors to another types such as int, float, double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3])\n",
      "tensor([False,  True,  True,  True])\n",
      "tensor([0, 1, 2, 3], dtype=torch.int16)\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([0., 1., 2., 3.], dtype=torch.float16)\n",
      "tensor([0., 1., 2., 3.])\n",
      "tensor([0., 1., 2., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(4)\n",
    "\n",
    "print(tensor)\n",
    "print(tensor.bool()) # convert to boolen(True/False)\n",
    "print(tensor.short()) # int16\n",
    "print(tensor.long()) # int64(Important)\n",
    "print(tensor.half()) # float16\n",
    "print(tensor.float()) # float32 (Important)\n",
    "print(tensor.double()) #float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Array to tensor conversion\n",
    "np.array = np.zeros((5,5))\n",
    "tensor = torch.from_numpy(np.array)\n",
    "print(tensor)\n",
    "np_array_back = tensor.numpy() # tensors to numpy array conversion\n",
    "print(np_array_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor Math and Comparison Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 10, 10])\n",
      "tensor([10., 10., 10.])\n",
      "tensor([10, 10, 10])\n",
      "tensor([-8, -6, -4])\n",
      "tensor([0.1111, 0.2500, 0.4286])\n",
      "tensor([1, 4, 9])\n",
      "tensor([81, 64, 49])\n",
      "tensor([False,  True,  True])\n",
      "tensor([[0.9931, 1.0405, 0.5401],\n",
      "        [0.6497, 0.6277, 0.3308]])\n",
      "tensor([[0.7793, 1.6455, 1.2982, 1.5544, 1.1139],\n",
      "        [0.9702, 2.4481, 0.7496, 1.5456, 0.8560],\n",
      "        [1.3747, 2.9719, 2.2792, 2.7256, 1.9981],\n",
      "        [0.9862, 2.3605, 1.2492, 1.8267, 1.1690],\n",
      "        [1.4289, 2.9912, 2.6481, 2.9594, 2.2614]])\n",
      "tensor([ 9, 16, 21])\n",
      "tensor(46)\n",
      "tensor([[[4.2381, 5.3324, 5.9481,  ..., 4.3729, 3.8477, 5.4150],\n",
      "         [3.2579, 4.0703, 3.9165,  ..., 3.6509, 3.9955, 4.7304],\n",
      "         [3.4659, 4.6081, 3.3981,  ..., 3.6503, 4.0255, 4.5042],\n",
      "         ...,\n",
      "         [4.6337, 6.6107, 5.8878,  ..., 5.0533, 5.5995, 6.0946],\n",
      "         [4.2729, 6.0616, 5.9226,  ..., 4.2567, 3.9056, 5.7997],\n",
      "         [4.5602, 6.1515, 4.9019,  ..., 4.9096, 5.1226, 6.0385]],\n",
      "\n",
      "        [[4.1005, 4.5048, 3.0624,  ..., 5.2636, 3.9644, 4.8080],\n",
      "         [4.2396, 4.2299, 3.4885,  ..., 6.1109, 4.1874, 4.7916],\n",
      "         [5.9706, 5.6110, 4.1494,  ..., 5.9611, 5.8642, 6.2770],\n",
      "         ...,\n",
      "         [4.6410, 3.8997, 2.9548,  ..., 4.6124, 4.0652, 4.6737],\n",
      "         [5.6701, 5.2414, 3.5902,  ..., 5.0300, 5.1069, 6.0619],\n",
      "         [5.0071, 4.9668, 4.3415,  ..., 6.1308, 5.0540, 5.4781]],\n",
      "\n",
      "        [[4.7875, 2.7739, 4.4912,  ..., 3.2741, 3.7753, 3.4124],\n",
      "         [6.1471, 3.2359, 5.2067,  ..., 4.9337, 4.4011, 5.3662],\n",
      "         [5.7530, 3.9580, 4.6906,  ..., 5.2781, 4.9854, 5.1315],\n",
      "         ...,\n",
      "         [6.0034, 5.0082, 5.1489,  ..., 6.2619, 5.2915, 5.9430],\n",
      "         [5.8528, 3.4239, 4.9702,  ..., 5.1461, 4.3942, 4.5623],\n",
      "         [6.2002, 3.8697, 4.6122,  ..., 6.1233, 4.5758, 5.4642]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[3.3534, 3.0716, 4.9684,  ..., 5.8292, 4.2914, 5.6260],\n",
      "         [4.9754, 4.8459, 5.1377,  ..., 6.0079, 5.2578, 5.7344],\n",
      "         [4.5979, 4.4951, 4.5192,  ..., 5.9253, 3.7423, 5.9690],\n",
      "         ...,\n",
      "         [6.0043, 6.1987, 6.2821,  ..., 8.4136, 5.9130, 8.3205],\n",
      "         [3.6187, 3.3402, 3.9173,  ..., 4.1762, 2.7294, 4.2787],\n",
      "         [2.6034, 2.8357, 3.4190,  ..., 3.8205, 2.5429, 3.8169]],\n",
      "\n",
      "        [[3.1222, 4.9780, 3.9376,  ..., 4.5384, 4.3120, 3.8585],\n",
      "         [4.9863, 7.4541, 6.0947,  ..., 6.2046, 5.3059, 5.6344],\n",
      "         [4.4462, 5.5570, 5.8161,  ..., 5.4253, 5.6633, 4.2965],\n",
      "         ...,\n",
      "         [3.5122, 4.4580, 3.8169,  ..., 3.5318, 3.2924, 4.0463],\n",
      "         [3.7585, 4.8356, 4.4517,  ..., 4.3324, 4.4535, 5.4242],\n",
      "         [4.3393, 4.7693, 5.4221,  ..., 4.7277, 5.0321, 5.0867]],\n",
      "\n",
      "        [[3.7201, 3.1112, 4.2834,  ..., 4.1927, 5.0897, 5.3282],\n",
      "         [4.1453, 3.8007, 5.2628,  ..., 4.7066, 4.7580, 4.7980],\n",
      "         [4.9914, 4.3619, 6.4427,  ..., 4.1716, 5.4735, 6.3421],\n",
      "         ...,\n",
      "         [4.8184, 4.7754, 5.7823,  ..., 4.9662, 6.2470, 5.7108],\n",
      "         [5.2026, 4.0379, 6.0183,  ..., 4.6861, 6.4788, 6.6757],\n",
      "         [5.0375, 4.1459, 5.6535,  ..., 4.8442, 5.6191, 6.2290]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3])\n",
    "y = torch.tensor([9,8,7])\n",
    "\n",
    "# Addition\n",
    "add = x + y\n",
    "print(add)\n",
    "\n",
    "# we can do this in two other ways\n",
    "add = torch.empty(3)\n",
    "torch.add(x,y,out=add) \n",
    "print(add) # this actually took float\n",
    "\n",
    "add = torch.add(x,y)\n",
    "print(add)\n",
    "\n",
    "# subtraction\n",
    "substract = x-y\n",
    "print(substract)\n",
    "\n",
    "# Division\n",
    "div = torch.true_divide(x,y) # if x and y are of equal shape then this function will do the element wise division.\n",
    "print(div)\n",
    "\n",
    "# Inline operation: It will mutate the tensors in place so it does not create a copy. This is more computationally efficient\n",
    "t = torch.zeros(3)\n",
    "t.add_(x)\n",
    "\n",
    "# Exponentiation\n",
    "z = x.pow(2) # this is going to be element wise power of 2\n",
    "print(z)\n",
    "\n",
    "# same operation can be done using the following way as well\n",
    "z = y**2\n",
    "print(z)\n",
    "\n",
    "# Simple Comparison\n",
    "z = x>=2 # element wise comparison\n",
    "print(z)\n",
    "\n",
    "# Matrix Multiplication\n",
    "\n",
    "x1 = torch.rand((2,5))\n",
    "x2 = torch.rand((5,3))\n",
    "\n",
    "x3 = torch.mm(x1,x2) # 2x3 matrix\n",
    "print(x3)\n",
    "\n",
    "# Matrix exponentiation\n",
    "matrix_exp = torch.rand(5,5)\n",
    "print(matrix_exp.matrix_power(3))\n",
    "\n",
    "# Element wise multiplication\n",
    "z = x*y\n",
    "print(z)\n",
    "\n",
    "# dot product\n",
    "print(torch.dot(x,y))\n",
    "\n",
    "# Batch Matrix Multiplication\n",
    "batch = 32\n",
    "n = 18\n",
    "m = 20\n",
    "p = 30\n",
    "\n",
    "tensor1 = torch.rand((batch, n, m))\n",
    "tensor2 = torch.rand((batch, m, p))\n",
    "out_bmm = torch.bmm(tensor1,tensor2) # here the resulting sape is going to be batch X n X p\n",
    "print(out_bmm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8348, -0.0798,  0.0364, -0.5262,  0.6617],\n",
      "        [-0.5570,  0.2229, -0.0034,  0.0691,  0.6039],\n",
      "        [-0.3877,  0.0316, -0.0850, -0.4416,  0.3508],\n",
      "        [ 0.0348, -0.1991, -0.4018, -0.0495,  0.6090],\n",
      "        [-0.0684,  0.1269,  0.1443,  0.0906,  0.3377]])\n",
      "tensor([[0.0405, 0.6325, 0.8313, 0.3258, 0.9868],\n",
      "        [0.3574, 0.8234, 0.7995, 0.8614, 0.9688],\n",
      "        [0.5239, 0.7136, 0.7330, 0.4142, 0.8789],\n",
      "        [0.9079, 0.5180, 0.4500, 0.7661, 0.9704],\n",
      "        [0.8171, 0.7717, 0.9153, 0.8783, 0.8737]])\n"
     ]
    }
   ],
   "source": [
    "# Example of broadcasting which refers as the dimention automatically expands\n",
    "\n",
    "x1 = torch.rand((5,5))\n",
    "x2 = torch.rand((1,5))\n",
    "\n",
    "z = x1-x2 \n",
    "print(z)\n",
    "''' In order to do mathematical operation in matrix x1's coulmn and x2's row should be matched, \n",
    "but pytorch can do this operation by broadcasting. \n",
    "Also as x2 has only one row it is also consider as a vector. \n",
    "So, the row of x2 will expand in order to match the row of x1. '''\n",
    "\n",
    "z = x1**x2\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some other useful Tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6)\n",
      "tensor(3) tensor(2)\n",
      "tensor(1) tensor(0)\n",
      "tensor([1, 2, 3])\n",
      "tensor([1, 2, 3])\n",
      "tensor(2)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(2.)\n",
      "tensor([False, False, False])\n",
      "tensor([7, 8, 9]) tensor([2, 1, 0])\n",
      "tensor([5, 5, 5])\n",
      "tensor(True)\n",
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "sum_x = torch.sum(x, dim=0) # summation of x tensor\n",
    "print(sum_x)\n",
    "\n",
    "values, indices = torch.max(x,dim=0) # dim = 0 means vector\n",
    "print(values, indices)\n",
    "values, indices = torch.min(x,dim=0) \n",
    "print(values, indices)\n",
    "\n",
    "abs_x = torch.abs(x) # absolute\n",
    "print(abs_x)\n",
    "abs_x = x.abs()\n",
    "print(abs_x)\n",
    "\n",
    "z = torch.argmax(x, dim=0) # maxium argument/index\n",
    "print(z)\n",
    "z = x.argmax(dim=0)\n",
    "print(z)\n",
    "\n",
    "z = torch.argmin(x, dim=0) # minium argument/index\n",
    "print(z)\n",
    "z = x.argmin(dim=0)\n",
    "print(z)\n",
    "\n",
    "mean_x = torch.mean(x.float(),dim=0) # need to convert the type\n",
    "print(mean_x)\n",
    "\n",
    "z = torch.eq(x,y)\n",
    "print(z)\n",
    "\n",
    "sorted_y, indices = torch.sort(y, dim=0, descending=False)\n",
    "print(sorted_y, indices)\n",
    "\n",
    "z = torch.clamp(x, min=5) # it means if the numbers in tensors are less than 5 than clamp will set them to 5 according the minimum number that are given\n",
    "print(z)\n",
    "\n",
    "x_ = torch.tensor([1,0,1,1], dtype=torch.bool)\n",
    "z = torch.any(x_)\n",
    "print(z)\n",
    "z = torch.all(x_)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5393, 0.6869, 0.8288, 0.6741, 0.1927, 0.8545, 0.0163, 0.0348, 0.6801,\n",
      "         0.6259, 0.3022, 0.6894, 0.7974, 0.2682, 0.1275],\n",
      "        [0.8488, 0.3128, 0.9031, 0.7936, 0.1774, 0.8228, 0.2481, 0.4913, 0.4897,\n",
      "         0.9311, 0.3996, 0.0611, 0.9340, 0.1657, 0.5322],\n",
      "        [0.2726, 0.1205, 0.4681, 0.2117, 0.6555, 0.6519, 0.2258, 0.6417, 0.1670,\n",
      "         0.6236, 0.1237, 0.9501, 0.1984, 0.6873, 0.3710],\n",
      "        [0.5691, 0.5202, 0.4607, 0.0246, 0.9611, 0.8418, 0.6211, 0.5605, 0.7948,\n",
      "         0.2943, 0.4455, 0.4311, 0.3983, 0.9736, 0.2689],\n",
      "        [0.8611, 0.2444, 0.0199, 0.5896, 0.1082, 0.9319, 0.2765, 0.5471, 0.0208,\n",
      "         0.7687, 0.9707, 0.4730, 0.8696, 0.1027, 0.0259],\n",
      "        [0.7018, 0.7830, 0.6700, 0.3161, 0.8329, 0.4719, 0.0097, 0.9065, 0.2836,\n",
      "         0.0111, 0.5266, 0.8768, 0.4583, 0.5706, 0.1775],\n",
      "        [0.2941, 0.3834, 0.0794, 0.6196, 0.5731, 0.7413, 0.6355, 0.6442, 0.7356,\n",
      "         0.0134, 0.0511, 0.9553, 0.5135, 0.9518, 0.3686],\n",
      "        [0.9148, 0.3531, 0.4863, 0.1109, 0.2720, 0.8589, 0.7026, 0.8069, 0.4756,\n",
      "         0.3660, 0.7173, 0.3497, 0.1762, 0.8707, 0.2640],\n",
      "        [0.4199, 0.5147, 0.5413, 0.8151, 0.3954, 0.4111, 0.1275, 0.0136, 0.7718,\n",
      "         0.5310, 0.2661, 0.3536, 0.2571, 0.5994, 0.3022],\n",
      "        [0.7706, 0.7612, 0.3227, 0.5893, 0.5435, 0.1643, 0.9523, 0.2899, 0.6117,\n",
      "         0.2604, 0.6082, 0.9830, 0.2502, 0.5053, 0.9212]])\n",
      "tensor([0.5393, 0.6869, 0.8288, 0.6741, 0.1927, 0.8545, 0.0163, 0.0348, 0.6801,\n",
      "        0.6259, 0.3022, 0.6894, 0.7974, 0.2682, 0.1275])\n",
      "tensor([0.5393, 0.8488, 0.2726, 0.5691, 0.8611, 0.7018, 0.2941, 0.9148, 0.4199,\n",
      "        0.7706])\n",
      "tensor([0.2726, 0.1205, 0.4681, 0.2117, 0.6555, 0.6519, 0.2258, 0.6417, 0.1670,\n",
      "        0.6236])\n",
      "torch.Size([15])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "features = 15\n",
    "\n",
    "x = torch.rand(batch_size, features)\n",
    "print(x)\n",
    "print(x[0]) # it will print all the 15 features of 0th index\n",
    "print(x[:,0]) # first feature in all of our example\n",
    "print(x[2,0:10]) # take 10 features from the 3rd index\n",
    "# lets see the shape in bothe the cases\n",
    "print(x[0].shape)\n",
    "print(x[:,0].shape)\n",
    "print(x[2,0:10].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 5, 8])\n",
      "tensor([0.9693, 0.6922])\n",
      "torch.Size([2])\n",
      "tensor([0, 1, 9])\n",
      "tensor([], dtype=torch.int64)\n",
      "tensor([0, 2, 4, 6, 8])\n",
      "tensor([ 0,  2,  4,  6,  8, 10,  6,  7,  8,  9])\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "1\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# fancy indexing\n",
    "x = torch.arange(10)\n",
    "indices = [2,5,8]\n",
    "print(x[indices])\n",
    "\n",
    "x = torch.rand(3,5) \n",
    "''' The torch.rand() function generates a tensor filled with random values sampled from a uniform distribution in the range [0, 1). \n",
    "This means that all values will be random floats between 0 (inclusive) and 1 (exclusive).'''\n",
    "rows = torch.tensor([1,0]) # this means row 1 and 0 is taken\n",
    "cols = torch.tensor([4,0]) # column 4 and 0 taken\n",
    "print(x[rows,cols]) # x[1,4],x[0,0]\n",
    "print(x[rows,cols].shape)\n",
    "\n",
    "x = torch.arange(10)\n",
    "print(x[(x<2)|(x>8)])\n",
    "print(x[(x<2)&(x>8)])\n",
    "print(x[x.remainder(2)==0]) # even index\n",
    "\n",
    "print(torch.where(x>5,x,x*2)) # conditional indexing\n",
    "print(torch.tensor([0,0,1,1,2,3,4]).unique()) \n",
    "print(x.ndimension()) # number of dimensions\n",
    "print(x.numel()) # number of elements in x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
