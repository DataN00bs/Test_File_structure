{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First lesson: Tensor Math and Comparison Operations: \n",
    "-  Tensor indexing\n",
    "-  Tensor Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. what is a tensor and how to create a tensor?\n",
    "- Tensor is multi-dimentional matrix containing elements of a single data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor = torch.tensor([[1,2,3],[4,5,6]])\n",
    "my_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor.size() # 2X3 tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Can we also set the type while initializing? Yes\n",
    "3. How?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor = torch.tensor([[1,2,3],[4,5,6]],dtype=torch.float32)\n",
    "my_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]], device='cuda:0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "my_tensor =  torch.tensor([[1,2,3],[4,5,6]],device=device)\n",
    "my_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "cuda:0\n",
      "torch.Size([2, 3])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(my_tensor.dtype)\n",
    "print(my_tensor.device)\n",
    "print(my_tensor.shape) # 2 rows and 3 columns\n",
    "print(my_tensor.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0.1035, 0.3877, 0.7842],\n",
      "        [0.9629, 0.5405, 0.9829],\n",
      "        [0.4155, 0.2939, 0.7920]], dtype=torch.float16)\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1]], dtype=torch.int16)\n",
      "torch.float32\n",
      "torch.float32\n",
      "torch.float16\n",
      "torch.float32\n",
      "torch.int16\n",
      "tensor([[1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1]], dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "# create an zero 3*3 tensor\n",
    "x = torch.empty(size = (3,3))\n",
    "print(x)\n",
    "\n",
    "y = torch.zeros(3,3)\n",
    "print(y)\n",
    "\n",
    "# initializing random tensors\n",
    "f = torch.rand(3,3, dtype=torch.float16)\n",
    "print(f)\n",
    "\n",
    "# initializing ones tensor\n",
    "z = torch.ones(3,3)\n",
    "print(z)\n",
    "\n",
    "# initializing identical tensor\n",
    "i = torch.eye(5,5, dtype=torch.int16)\n",
    "print(i)\n",
    "\n",
    "# remember by default the data type is float32 in tensors\n",
    "print(x.dtype)\n",
    "print(y.dtype)\n",
    "print(f.dtype)\n",
    "print(z.dtype)\n",
    "print(i.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(start=0, end=5, step=1) # this is kind range, which we apply in loop \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000, 0.9000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.linspace(start=0.1,end=1,steps=10) # this fuction also work as loop\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n.b: remember that torch is core library of pytorch framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6199,  0.4872, -0.0413,  1.3820, -1.1765]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(1,5).normal_(mean=0,std=1) # initializing normal distribution, here std is standard deviation.\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5779, 0.8102, 0.9275, 0.1023, 0.7566]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(1,5).uniform_(0,1) # initializing uniform distribution\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.diag(torch.ones(3)) # another way to initialize identity matrix\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to initialize and convert tensors to another types such as int, float, double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3])\n",
      "tensor([False,  True,  True,  True])\n",
      "tensor([0, 1, 2, 3], dtype=torch.int16)\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([0., 1., 2., 3.], dtype=torch.float16)\n",
      "tensor([0., 1., 2., 3.])\n",
      "tensor([0., 1., 2., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(4)\n",
    "\n",
    "print(tensor)\n",
    "print(tensor.bool()) # convert to boolen(True/False)\n",
    "print(tensor.short()) # int16\n",
    "print(tensor.long()) # int64(Important)\n",
    "print(tensor.half()) # float16\n",
    "print(tensor.float()) # float32 (Important)\n",
    "print(tensor.double()) #float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Array to tensor conversion\n",
    "np.array = np.zeros((5,5))\n",
    "tensor = torch.from_numpy(np.array)\n",
    "print(tensor)\n",
    "np_array_back = tensor.numpy() # tensors to numpy array conversion\n",
    "print(np_array_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor Math and Comparison Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition: \n",
      "tensor([10, 10, 10])\n",
      "\n",
      "Addition: \n",
      "tensor([10., 10., 10.])\n",
      "\n",
      "Addition: \n",
      "tensor([10, 10, 10])\n",
      "\n",
      "Substraction: \n",
      "tensor([-8, -6, -4])\n",
      "\n",
      "Multiplication: \n",
      "tensor([ 9, 16, 21])\n",
      "\n",
      "Multiplication: \n",
      "tensor([ 9, 16, 21])\n",
      "\n",
      "Division: \n",
      "tensor([0.1111, 0.2500, 0.4286])\n",
      "\n",
      "Division: \n",
      "tensor([0.1111, 0.2500, 0.4286])\n",
      "\n",
      "Inline addition: \n",
      "tensor([1., 2., 3.])\n",
      "\n",
      "Exponent operation: \n",
      "tensor([1, 4, 9])\n",
      "\n",
      "Exponent operation: \n",
      "tensor([81, 64, 49])\n",
      "\n",
      "Comparison operation: \n",
      "tensor([False,  True,  True])\n",
      "\n",
      "Matrix Multiplication: \n",
      "tensor([[1.0745, 0.8961, 1.1154],\n",
      "        [1.4188, 1.4805, 1.7147]])\n",
      "\n",
      "Matrix Exponentiation: \n",
      "tensor([[6.6764, 4.7321, 3.3850, 5.4056, 8.2055],\n",
      "        [7.1324, 4.8272, 3.5300, 5.4811, 8.4673],\n",
      "        [4.1117, 2.8904, 2.0978, 3.3235, 5.0634],\n",
      "        [6.7270, 4.6581, 3.3548, 5.1807, 8.0578],\n",
      "        [4.6045, 3.0566, 2.2322, 3.3903, 5.3406]])\n",
      "\n",
      "Dot Product: \n",
      "46\n",
      "\n",
      "Batch Matrix Multiplication: \n",
      "tensor([[[5.6502, 3.2130, 3.3010,  ..., 5.8226, 4.5997, 4.5176],\n",
      "         [5.5289, 3.2088, 3.5162,  ..., 5.5685, 4.2337, 4.7813],\n",
      "         [6.3851, 3.6496, 4.9697,  ..., 6.2940, 6.1860, 6.0211],\n",
      "         ...,\n",
      "         [6.6712, 4.6184, 4.4936,  ..., 6.7229, 5.7068, 5.4366],\n",
      "         [6.3872, 4.0398, 4.0919,  ..., 6.8319, 6.2022, 6.1738],\n",
      "         [6.0237, 3.7712, 4.0659,  ..., 6.4220, 5.2557, 5.2285]],\n",
      "\n",
      "        [[6.4230, 7.2015, 5.1219,  ..., 5.2599, 7.3519, 5.9450],\n",
      "         [5.7051, 6.7533, 3.7148,  ..., 4.5360, 6.3646, 4.8478],\n",
      "         [4.3703, 5.6789, 3.5826,  ..., 4.7609, 4.6944, 4.4150],\n",
      "         ...,\n",
      "         [4.4706, 5.8012, 3.2567,  ..., 3.7125, 5.0863, 4.0364],\n",
      "         [4.3246, 5.0514, 3.9969,  ..., 3.9661, 5.4313, 3.9444],\n",
      "         [4.7450, 5.6462, 4.3733,  ..., 3.7719, 6.9170, 4.0164]],\n",
      "\n",
      "        [[4.8873, 5.4232, 5.5584,  ..., 6.4540, 5.4479, 6.6998],\n",
      "         [3.7613, 4.0228, 3.4822,  ..., 4.5163, 4.0134, 3.7521],\n",
      "         [6.5098, 5.5832, 6.0366,  ..., 6.9447, 6.0637, 6.5482],\n",
      "         ...,\n",
      "         [5.2902, 4.7912, 5.2826,  ..., 5.0177, 4.5443, 4.8348],\n",
      "         [5.4731, 5.6836, 5.3385,  ..., 6.5433, 5.6467, 6.5569],\n",
      "         [5.3564, 4.8966, 4.7530,  ..., 5.2702, 4.3669, 5.3764]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[5.4094, 4.6985, 4.7364,  ..., 4.9145, 5.4210, 4.4433],\n",
      "         [5.6638, 4.0274, 4.9108,  ..., 4.1652, 4.8024, 3.7544],\n",
      "         [5.8175, 4.6165, 5.0735,  ..., 3.9185, 4.5816, 3.9548],\n",
      "         ...,\n",
      "         [5.8040, 5.1373, 4.7220,  ..., 5.3588, 5.0822, 4.3064],\n",
      "         [6.5051, 4.8218, 5.7660,  ..., 5.6435, 5.1814, 4.4816],\n",
      "         [7.2312, 6.0317, 6.9097,  ..., 7.3486, 6.4811, 5.3592]],\n",
      "\n",
      "        [[6.2997, 6.6043, 5.1184,  ..., 4.0071, 5.8855, 5.0733],\n",
      "         [5.3304, 5.8297, 5.0427,  ..., 3.9991, 5.3527, 4.4890],\n",
      "         [7.0970, 7.5259, 6.3437,  ..., 5.0169, 5.1537, 5.7883],\n",
      "         ...,\n",
      "         [4.4745, 5.0132, 4.2769,  ..., 2.9574, 4.5351, 3.8927],\n",
      "         [5.4103, 6.4986, 5.3145,  ..., 3.9308, 5.7126, 4.1377],\n",
      "         [4.9068, 4.4187, 3.4706,  ..., 2.5911, 4.6953, 3.7634]],\n",
      "\n",
      "        [[5.5522, 4.9492, 5.0151,  ..., 6.8001, 6.3755, 6.3323],\n",
      "         [5.1781, 4.7925, 5.0019,  ..., 5.9503, 6.4050, 6.2448],\n",
      "         [5.3253, 4.7099, 4.5136,  ..., 6.0230, 6.3662, 5.6211],\n",
      "         ...,\n",
      "         [5.1258, 4.2226, 4.5568,  ..., 5.7332, 6.4057, 6.1296],\n",
      "         [5.8741, 5.3689, 5.3811,  ..., 7.3595, 7.2611, 6.7023],\n",
      "         [3.7531, 3.7351, 4.2126,  ..., 4.8394, 6.2952, 5.3910]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3])\n",
    "y = torch.tensor([9,8,7])\n",
    "\n",
    "# Addition\n",
    "add = x + y\n",
    "print(f\"Addition: \\n{add}\\n\")\n",
    "\n",
    "# we can do this in two other ways\n",
    "add = torch.empty(3)\n",
    "torch.add(x,y,out=add) \n",
    "print(f\"Addition: \\n{add}\\n\") # this actually took float\n",
    "\n",
    "add = torch.add(x,y)\n",
    "print(f\"Addition: \\n{add}\\n\")\n",
    "\n",
    "# subtraction\n",
    "substract = x-y\n",
    "print(f\"Substraction: \\n{substract}\\n\")\n",
    "\n",
    "# Element wise multiplication\n",
    "multiply = x*y\n",
    "print(f\"Multiplication: \\n{multiply}\\n\")\n",
    "\n",
    "multiply = torch.mul(x,y)\n",
    "print(f\"Multiplication: \\n{multiply}\\n\")\n",
    "\n",
    "# Division\n",
    "div = torch.true_divide(x,y) # if x and y are of equal shape then this function will do the element wise division.\n",
    "print(f\"Division: \\n{div}\\n\")\n",
    "\n",
    "div = x/y\n",
    "print(f\"Division: \\n{div}\\n\")\n",
    "\n",
    "# Inline operation: It will mutate the tensors in place so it does not create a copy. This is more computationally efficient\n",
    "t = torch.zeros(3)\n",
    "print(f\"Inline addition: \\n{t.add_(x)}\\n\")\n",
    "\n",
    "# Exponentiation\n",
    "z = x.pow(2) # this is going to be element wise power of 2\n",
    "print(f\"Exponent operation: \\n{z}\\n\")\n",
    "\n",
    "# same operation can be done using the following way as well\n",
    "z = y**2\n",
    "print(f\"Exponent operation: \\n{z}\\n\")\n",
    "\n",
    "# Simple Comparison\n",
    "z = x>=2 # element wise comparison\n",
    "print(f\"Comparison operation: \\n{z}\\n\")\n",
    "\n",
    "# Matrix Multiplication\n",
    "x1 = torch.rand((2,5))\n",
    "x2 = torch.rand((5,3))\n",
    "\n",
    "x3 = torch.mm(x1,x2) # 2x3 matrix\n",
    "print(f\"Matrix Multiplication: \\n{x3}\\n\")\n",
    "\n",
    "# Matrix exponentiation\n",
    "matrix_exp = torch.rand(5,5)\n",
    "print(f\"Matrix Exponentiation: \\n{matrix_exp.matrix_power(3)}\\n\")\n",
    "\n",
    "# dot product\n",
    "print(f\"Dot Product: \\n{torch.dot(x,y)}\\n\")\n",
    "\n",
    "# Batch Matrix Multiplication\n",
    "batch = 32\n",
    "n = 18\n",
    "m = 20\n",
    "p = 30\n",
    "\n",
    "tensor1 = torch.rand((batch, n, m))\n",
    "tensor2 = torch.rand((batch, m, p))\n",
    "out_bmm = torch.bmm(tensor1,tensor2) # here the resulting sape is going to be batch X n X p\n",
    "print(f\"Batch Matrix Multiplication: \\n{out_bmm}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8348, -0.0798,  0.0364, -0.5262,  0.6617],\n",
      "        [-0.5570,  0.2229, -0.0034,  0.0691,  0.6039],\n",
      "        [-0.3877,  0.0316, -0.0850, -0.4416,  0.3508],\n",
      "        [ 0.0348, -0.1991, -0.4018, -0.0495,  0.6090],\n",
      "        [-0.0684,  0.1269,  0.1443,  0.0906,  0.3377]])\n",
      "tensor([[0.0405, 0.6325, 0.8313, 0.3258, 0.9868],\n",
      "        [0.3574, 0.8234, 0.7995, 0.8614, 0.9688],\n",
      "        [0.5239, 0.7136, 0.7330, 0.4142, 0.8789],\n",
      "        [0.9079, 0.5180, 0.4500, 0.7661, 0.9704],\n",
      "        [0.8171, 0.7717, 0.9153, 0.8783, 0.8737]])\n"
     ]
    }
   ],
   "source": [
    "# Example of broadcasting which refers as the dimention automatically expands\n",
    "\n",
    "x1 = torch.rand((5,5))\n",
    "x2 = torch.rand((1,5))\n",
    "\n",
    "z = x1-x2 \n",
    "print(z)\n",
    "''' In order to do mathematical operation in matrix x1's coulmn and x2's row should be matched, \n",
    "but pytorch can do this operation by broadcasting. \n",
    "Also as x2 has only one row it is also consider as a vector. \n",
    "So, the row of x2 will expand in order to match the row of x1. '''\n",
    "\n",
    "z = x1**x2\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some other useful Tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6)\n",
      "tensor(3) tensor(2)\n",
      "tensor(1) tensor(0)\n",
      "tensor([1, 2, 3])\n",
      "tensor([1, 2, 3])\n",
      "tensor(2)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(2.)\n",
      "tensor([False, False, False])\n",
      "tensor([7, 8, 9]) tensor([2, 1, 0])\n",
      "tensor([5, 5, 5])\n",
      "tensor(True)\n",
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "sum_x = torch.sum(x, dim=0) # summation of x tensor\n",
    "print(sum_x)\n",
    "\n",
    "values, indices = torch.max(x,dim=0) # dim = 0 means vector\n",
    "print(values, indices)\n",
    "values, indices = torch.min(x,dim=0) \n",
    "print(values, indices)\n",
    "\n",
    "abs_x = torch.abs(x) # absolute\n",
    "print(abs_x)\n",
    "abs_x = x.abs()\n",
    "print(abs_x)\n",
    "\n",
    "z = torch.argmax(x, dim=0) # maxium argument/index\n",
    "print(z)\n",
    "z = x.argmax(dim=0)\n",
    "print(z)\n",
    "\n",
    "z = torch.argmin(x, dim=0) # minium argument/index\n",
    "print(z)\n",
    "z = x.argmin(dim=0)\n",
    "print(z)\n",
    "\n",
    "mean_x = torch.mean(x.float(),dim=0) # need to convert the type\n",
    "print(mean_x)\n",
    "\n",
    "z = torch.eq(x,y)\n",
    "print(z)\n",
    "\n",
    "sorted_y, indices = torch.sort(y, dim=0, descending=False)\n",
    "print(sorted_y, indices)\n",
    "\n",
    "z = torch.clamp(x, min=5) # it means if the numbers in tensors are less than 5 than clamp will set them to 5 according the minimum number that are given\n",
    "print(z)\n",
    "\n",
    "x_ = torch.tensor([1,0,1,1], dtype=torch.bool)\n",
    "z = torch.any(x_)\n",
    "print(z)\n",
    "z = torch.all(x_)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5393, 0.6869, 0.8288, 0.6741, 0.1927, 0.8545, 0.0163, 0.0348, 0.6801,\n",
      "         0.6259, 0.3022, 0.6894, 0.7974, 0.2682, 0.1275],\n",
      "        [0.8488, 0.3128, 0.9031, 0.7936, 0.1774, 0.8228, 0.2481, 0.4913, 0.4897,\n",
      "         0.9311, 0.3996, 0.0611, 0.9340, 0.1657, 0.5322],\n",
      "        [0.2726, 0.1205, 0.4681, 0.2117, 0.6555, 0.6519, 0.2258, 0.6417, 0.1670,\n",
      "         0.6236, 0.1237, 0.9501, 0.1984, 0.6873, 0.3710],\n",
      "        [0.5691, 0.5202, 0.4607, 0.0246, 0.9611, 0.8418, 0.6211, 0.5605, 0.7948,\n",
      "         0.2943, 0.4455, 0.4311, 0.3983, 0.9736, 0.2689],\n",
      "        [0.8611, 0.2444, 0.0199, 0.5896, 0.1082, 0.9319, 0.2765, 0.5471, 0.0208,\n",
      "         0.7687, 0.9707, 0.4730, 0.8696, 0.1027, 0.0259],\n",
      "        [0.7018, 0.7830, 0.6700, 0.3161, 0.8329, 0.4719, 0.0097, 0.9065, 0.2836,\n",
      "         0.0111, 0.5266, 0.8768, 0.4583, 0.5706, 0.1775],\n",
      "        [0.2941, 0.3834, 0.0794, 0.6196, 0.5731, 0.7413, 0.6355, 0.6442, 0.7356,\n",
      "         0.0134, 0.0511, 0.9553, 0.5135, 0.9518, 0.3686],\n",
      "        [0.9148, 0.3531, 0.4863, 0.1109, 0.2720, 0.8589, 0.7026, 0.8069, 0.4756,\n",
      "         0.3660, 0.7173, 0.3497, 0.1762, 0.8707, 0.2640],\n",
      "        [0.4199, 0.5147, 0.5413, 0.8151, 0.3954, 0.4111, 0.1275, 0.0136, 0.7718,\n",
      "         0.5310, 0.2661, 0.3536, 0.2571, 0.5994, 0.3022],\n",
      "        [0.7706, 0.7612, 0.3227, 0.5893, 0.5435, 0.1643, 0.9523, 0.2899, 0.6117,\n",
      "         0.2604, 0.6082, 0.9830, 0.2502, 0.5053, 0.9212]])\n",
      "tensor([0.5393, 0.6869, 0.8288, 0.6741, 0.1927, 0.8545, 0.0163, 0.0348, 0.6801,\n",
      "        0.6259, 0.3022, 0.6894, 0.7974, 0.2682, 0.1275])\n",
      "tensor([0.5393, 0.8488, 0.2726, 0.5691, 0.8611, 0.7018, 0.2941, 0.9148, 0.4199,\n",
      "        0.7706])\n",
      "tensor([0.2726, 0.1205, 0.4681, 0.2117, 0.6555, 0.6519, 0.2258, 0.6417, 0.1670,\n",
      "        0.6236])\n",
      "torch.Size([15])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "features = 15\n",
    "\n",
    "x = torch.rand(batch_size, features)\n",
    "print(x)\n",
    "print(x[0]) # it will print all the 15 features of 0th index\n",
    "print(x[:,0]) # first feature in all of our example\n",
    "print(x[2,0:10]) # take 10 features from the 3rd index\n",
    "# lets see the shape in bothe the cases\n",
    "print(x[0].shape)\n",
    "print(x[:,0].shape)\n",
    "print(x[2,0:10].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 5, 8])\n",
      "tensor([0.9693, 0.6922])\n",
      "torch.Size([2])\n",
      "tensor([0, 1, 9])\n",
      "tensor([], dtype=torch.int64)\n",
      "tensor([0, 2, 4, 6, 8])\n",
      "tensor([ 0,  2,  4,  6,  8, 10,  6,  7,  8,  9])\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "1\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# fancy indexing\n",
    "x = torch.arange(10)\n",
    "indices = [2,5,8]\n",
    "print(x[indices])\n",
    "\n",
    "x = torch.rand(3,5) \n",
    "''' The torch.rand() function generates a tensor filled with random values sampled from a uniform distribution in the range [0, 1). \n",
    "This means that all values will be random floats between 0 (inclusive) and 1 (exclusive).'''\n",
    "rows = torch.tensor([1,0]) # this means row 1 and 0 is taken\n",
    "cols = torch.tensor([4,0]) # column 4 and 0 taken\n",
    "print(x[rows,cols]) # x[1,4],x[0,0]\n",
    "print(x[rows,cols].shape)\n",
    "\n",
    "x = torch.arange(10)\n",
    "print(x[(x<2)|(x>8)])\n",
    "print(x[(x<2)&(x>8)])\n",
    "print(x[x.remainder(2)==0]) # even index\n",
    "\n",
    "print(torch.where(x>5,x,x*2)) # conditional indexing\n",
    "print(torch.tensor([0,0,1,1,2,3,4]).unique()) \n",
    "print(x.ndimension()) # number of dimensions\n",
    "print(x.numel()) # number of elements in x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor Reshaping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[0, 3, 6],\n",
      "        [1, 4, 7],\n",
      "        [2, 5, 8]])\n",
      "tensor([0, 3, 6, 1, 4, 7, 2, 5, 8])\n",
      "torch.Size([4, 5])\n",
      "torch.Size([2, 10])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(9)\n",
    "print(x)\n",
    "x_3x3 = x.view(3,3)\n",
    "print(x_3x3)\n",
    "\n",
    "x_3x3 = x.reshape(3,3)\n",
    "#print(x_3x3)\n",
    "\n",
    "''' for view contigous memroy allocation is needed for reshape contigous memory is not needed, so it is better to use reshape '''\n",
    "\n",
    "y = x_3x3.t() # transpose\n",
    "print(y) \n",
    "print(y.reshape(9))  \n",
    "\n",
    "# concatenate\n",
    "x1 = torch.rand(2,5)\n",
    "x2 = torch.rand(2,5)\n",
    "\n",
    "print(torch.cat((x1,x2),dim=0).shape) # row wise concatenate\n",
    "print(torch.cat((x1,x2),dim=1).shape) # column wise concatenate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 5, 2])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([1, 1, 10])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "z = x1.view(-1) # flattening the x1 tensor\n",
    "print(z.shape)\n",
    "\n",
    "# flattening again with a bit more complicacy\n",
    "batch = 64\n",
    "x = torch.rand((batch, 2, 5))\n",
    "z = x.view(batch,-1)\n",
    "print(z.shape)\n",
    "\n",
    "# switching the axis\n",
    "z = x.permute(0,2,1)\n",
    "print(z.shape)\n",
    "\n",
    "x = torch.arange(10)\n",
    "print(x.unsqueeze(0).shape) # 1x10 vector\n",
    "print(x.unsqueeze(1).shape) # 10x1 vector\n",
    "\n",
    "x = torch.arange(10).unsqueeze(0).unsqueeze(1) #1x1x10\n",
    "print(x.shape)\n",
    "\n",
    "z = x.squeeze(1)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
